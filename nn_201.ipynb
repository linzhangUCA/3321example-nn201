{"cells":[{"cell_type":"markdown","metadata":{"id":"WXjKp5Q-lksO"},"source":["# Neural Network 201/N01\n","In this example, we will walk through two/multi-input single output neural network model. We will train a model to predict used cars' prices based on two features: age and mileage.\n","\n","The following contents will be covered:\n","1. Normalize the data.\n","2. Construct multi-input linear model.\n","3. Vector and matrix operations.\n","4. Sigmoid and Rectified linear unit (ReLU) activation.\n"]},{"cell_type":"markdown","metadata":{"id":"quxxsYbvlksR"},"source":["## Load Raw Data\n","Data is from [Used Car Dataset](https://www.kaggle.com/datasets/austinreese/craigslist-carstrucks-data). Data is prepocessed and shuffled. N/As and outliers were taken out. 90% are used for training the model. We'll use the rest 10% samples to evaluate and test the model. \n","\n","First, let's load the data as numpy arrays."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1694659674888,"user":{"displayName":"Lin Zhang","userId":"02863611533796321015"},"user_tz":300},"id":"2NFcnJf6lksS","outputId":"6680e9e7-7388-45e7-bb78-068a4ea42b8f"},"outputs":[{"name":"stdout","output_type":"stream","text":["age_train shape: (268577,)\n","mileage_train shape: (268577,)\n","price_train shape: (268577,)\n","age_test shape: (29842,)\n","mileage_test shape: (29842,)\n","price_test shape: (29842,)\n"]}],"source":["import numpy as np\n","age_train = np.load('age_train.npy')\n","mileage_train = np.load('mileage_train.npy')\n","price_train = np.load('price_train.npy')\n","age_test = np.load('age_test.npy')\n","mileage_test = np.load('mileage_test.npy')\n","price_test = np.load('price_test.npy')\n","print(f\"age_train shape: {age_train.shape}\")\n","print(f\"mileage_train shape: {mileage_train.shape}\")\n","print(f\"price_train shape: {age_train.shape}\")\n","print(f\"age_test shape: {age_test.shape}\")\n","print(f\"mileage_test shape: {mileage_test.shape}\")\n","print(f\"price_test shape: {age_test.shape}\")\n"]},{"cell_type":"markdown","metadata":{"id":"ID3xPmPDlksU"},"source":["## Visualize the Data\n","Use [matplotlib](https://matplotlib.org/). **Note**: `matplotlib` will auto scale the figure to better fill the space."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":448},"executionInfo":{"elapsed":987,"status":"ok","timestamp":1694659681625,"user":{"displayName":"Lin Zhang","userId":"02863611533796321015"},"user_tz":300},"id":"7rP5n86rlksU","outputId":"3e0d73b2-d956-4d1d-b2fd-bb8a195f2ddf"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","fig, axs = plt.subplots(2,1)\n","fig.set_figwidth(8)\n","fig.set_figheight(10)\n","axs[0] = plt.subplot(2,1,1)\n","axs[0].plot(age_train, price_train, '.', markersize=1)\n","axs[0].set(xlabel='Age (years)', ylabel='Price ($)')\n","axs[1] = plt.subplot(2,1,2)\n","axs[1].plot(mileage_train, price_train, '.', markersize=1)\n","axs[1].set(xlabel='Mileage (miles)', ylabel='Price ($)')\n"]},{"cell_type":"markdown","metadata":{},"source":["Visualize raw data in 3D space"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig = plt.figure()\n","ax = fig.add_subplot(111, projection='3d')\n","# Plot the data\n","scatter = ax.scatter3D(age_train, mileage_train, price_train, s=np.ones(price_train.size), c=price_train, cmap='coolwarm') \n","\n","ax.set_xlabel('Age (yrs)')\n","ax.set_ylabel('Mileage (miles)')\n","ax.set_zlabel('Price ($)')\n","\n","ax.view_init(elev=30, azim=-45)  # set elevation and azimuth of viewing angle\n","\n","# colorbar = fig.colorbar(scatter, ax=ax)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Pre-process the Data\n","1. Rescale `age`, `mileage` and `price` arrays to avoid large parameters in model. \n","2. Stack the rescaled `age` and `mileage` arrays to form a feature matrix, or a 2d-array with shape (M, 2). \n","3. Reshape rescaled `price` array to a column vector, or a 2d-array with shape (M, 1).\n","> M represents number of samples."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Rescale\n","# age_train_rescale = age_train / 10\n","# mileage_train_rescale = mileage_train / 1e4\n","# price_train_rescale = price_train / 1e4\n","# age_test_rescale = age_test / 10\n","# mileage_test_rescale = mileage_test / 1e4\n","# price_test_rescale = price_test / 1e4\n","age_train_rescale = age_train / age_train.max()\n","mileage_train_rescale = mileage_train / mileage_train.max()\n","price_train_rescale = price_train / price_train.max()\n","age_test_rescale = age_test / age_train.max()\n","mileage_test_rescale = mileage_test / mileage_train.max()\n","price_test_rescale = price_test / price_train.max()\n","\n","# Stack features\n","X_train = np.stack((age_train_rescale, mileage_train_rescale), axis=1)\n","X_test = np.stack((age_test_rescale, mileage_test_rescale), axis=1)\n","# Reshape labels\n","y_train = price_train_rescale.reshape(-1, 1)\n","y_test = price_test_rescale.reshape(-1, 1)\n","print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)  # for debug\n","\n","fig = plt.figure()\n","fig.set_figwidth(7)\n","fig.set_figheight(7)\n","ax = fig.add_subplot(111, projection='3d')\n","# Plot the data\n","ax.scatter3D(X_train[:, 0], X_train[:, 1], y_train.squeeze(), s=np.ones(y_train.size), c=y_train.squeeze(), cmap='coolwarm') \n","\n","ax.set_xlabel(f'Age ({age_train.max()} yrs)')\n","ax.set_ylabel(f'Mileage ({mileage_train.max()} miles)')\n","ax.set_zlabel(f'Price (${price_train.max()})')\n","ax.zaxis.labelpad = -0.5 # display z label\n","\n","# ax.view_init(elev=30, azim=-45)  # set elevation and azimuth of viewing angle\n"]},{"cell_type":"markdown","metadata":{"id":"i1oW67_4lksU"},"source":["## Create an Initial Model\n","Create a linear model: $\\hat{y}=w_1x_1 + w_2x_2 + b$. Initialize three parameters, $w_1$, $w_2$ and $b$ to small values (close to 0).\n","\n","$\\hat{\\mathbf{y}} = \\mathbf{X} \\cdot \\mathbf{w}^T + \\mathbf{b}$"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":448},"executionInfo":{"elapsed":813,"status":"ok","timestamp":1694659685939,"user":{"displayName":"Lin Zhang","userId":"02863611533796321015"},"user_tz":300},"id":"9O5HK-sYlksV","outputId":"8a5da8e8-b1b5-438e-ab6b-d9b95b2dc75f"},"outputs":[],"source":["# Define model function\n","def linear(input, weight, bias):\n","    \"\"\" Model function\n","    Args:\n","        input: feature matrix (independent variables), 2d-array with shape (samples #, features #)\n","        weight: row vector of weights, 2d-array with shape (1, # features)\n","        bias: scalar\n","    Returns:\n","        output: column vector of predictions (dependent variables), 2d-array with shape (# samples, 1)\n","    \"\"\"\n","    output = input @ weight.T + bias\n","    return output\n","\n","# Initialize model parameters: w1, w2, b\n","w_guess = np.random.normal(0, 1e-4, (1, 2)) \n","b_guess = np.random.normal(0, 1e-4)\n","y_pred = linear(X_train, w_guess, b_guess)\n","\n","fig = plt.figure()\n","fig.set_figwidth(7)\n","fig.set_figheight(7)\n","ax = fig.add_subplot(111, projection='3d')\n","# Define the grid of points for the plane\n","x_grid = np.linspace(-0.1, 1.1, 100)\n","y_grid = np.linspace(-0.1, 1.1, 100)\n","x_mesh, y_mesh = np.meshgrid(x_grid, y_grid)\n","z_mesh = w_guess[0, 0] * x_mesh + w_guess[0, 1] * y_mesh + b_guess\n","# Plot the data\n","ax.scatter3D(X_train[:, 0], X_train[:, 1], y_train.squeeze(), s=np.ones(y_train.size), c=y_train.squeeze(), cmap='coolwarm') \n","ax.plot_surface(x_mesh, y_mesh, z_mesh, cmap='cool', antialiased=False, alpha=0.4)\n","\n","ax.set_xlabel(f'Age ({age_train.max()} yrs)')\n","ax.set_ylabel(f'Mileage ({mileage_train.max()} miles)')\n","ax.set_zlabel(f'Price (${price_train.max()})')\n","ax.zaxis.labelpad = -0.5 # display z label\n","\n","# ax.view_init(elev=30, azim=-45)  # set elevation and azimuth of viewing angle\n"]},{"cell_type":"markdown","metadata":{"id":"-2_2xnQ_lksV"},"source":["## Create Loss Function\n","Use Mean Square Error function to evaluate how bad the model was."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":225,"status":"ok","timestamp":1694659689782,"user":{"displayName":"Lin Zhang","userId":"02863611533796321015"},"user_tz":300},"id":"DoaZpBRqlksW","outputId":"3e25cf49-00c6-4ec6-aa4e-31d342072b71"},"outputs":[],"source":["def mse_loss(pred, label):\n","    \"\"\" Mean Square Error function\n","    Args:\n","        prediction: column vector of predictions, 2d-array with shape (# samples, 1)\n","        label: column vector of ground truths, 2d-array with shape (# samples, 1)\n","    Returns:\n","        loss_value: scalar\n","    \"\"\"\n","    loss_value = np.mean(0.5 * (pred - label) ** 2)\n","    return loss_value\n","\n","# Evaluate initial model\n","loss = mse_loss(pred=linear(X_train, w_guess, b_guess), label=y_train)\n","print(f\"mse loss: {loss}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Gradient Descent Optimization"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"ffjPIRwclksW"},"outputs":[],"source":["# Define gradient computation function\n","def grad(input, pred, label):\n","    \"\"\" Gradient function\n","    Args:\n","        prediction: column vector of predictions, 2d-array with shape (# samples, 1)\n","        target: column vector of ground truths, 2d-array with shape (# samples, 1)\n","        input: feature matrix, 2d-array with shape (# samples, # features)\n","    Returns:\n","        dw: row vector of MSE loss partial derivatives w.r.t. weights, 2d-array with shape (1, # features)\n","        db: scalar of MSE loss partial derivatives w.r.t. bias\n","    \"\"\"\n","    dw = 1 / label.shape[0] * ((pred - label).T @ input)  # dL/dw\n","    db = (pred - label).mean()  # dL/db\n","    \n","    return dw, db\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Gradient Descent Iterations"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["w = np.random.normal(0, 1e-4, (1, 2)) \n","b = np.random.normal(0, 1e-4)\n","print(f\"initial parameters: w = {w}, b = {b}\")\n","# Gradient descent optimization\n","num_iters = 2000\n","learning_rate = 0.02\n","losses = []\n","for i in range(num_iters):\n","    y_pred = linear(X_train, w, b)\n","    dw, db = grad(X_train, y_pred, y_train)\n","    loss = mse_loss(y_pred, y_train)\n","    w = w - learning_rate * dw\n","    b = b - learning_rate * db\n","    print(f\"loss @ {i+1} iteration: {loss}\")\n","    losses.append(loss)\n","print(f\"final parameters: w = {w}, b = {b}\")\n","\n","# Observe the loss change\n","plt.plot(losses)"]},{"cell_type":"markdown","metadata":{},"source":["## Assess Model on Training Data\n","Now, we can use the updated model with **updated** $w_1$, $w_2$ and $b$ to predict car prices."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Visualize model on training data\n","fig, axs = plt.subplots(2,1)  # Initialize figures in 2 rows, 1 column\n","fig.set_figwidth(8)  # set figure size\n","fig.set_figheight(10)\n","axs[0] = plt.subplot(2,1,1)  # plot in the first figure\n","axs[0].plot(X_train[:, 0], y_train, '.', markersize=1)  # draw blue dots\n","axs[0].plot(X_train[:, 0], y_pred, 'r+', markersize=2)  # draw red '+' markers\n","axs[0].set(xlabel=f'Age (Unit: {age_train.max()} years)', ylabel=f'Price (Unit: ${price_train.max()})')  # label axes\n","axs[0].grid()\n","axs[1] = plt.subplot(2,1,2)\n","axs[1].plot(X_train[:, 1], y_train, '.', markersize=1)\n","axs[1].plot(X_train[:, 1], y_pred, 'r+', markersize=2)\n","axs[1].set(xlabel=f'Mileage (Unit: {mileage_train.max()} miles)', ylabel=f'Price (Unit: ${price_train.max()})')\n","axs[1].grid()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig = plt.figure()\n","fig.set_figwidth(7)\n","fig.set_figheight(7)\n","ax = fig.add_subplot(111, projection='3d')\n","# Define the grid of points for the plane\n","z_mesh = w[0, 0] * x_mesh + w[0, 1] * y_mesh + b\n","# Plot the data\n","ax.scatter3D(X_train[:, 0], X_train[:, 1], y_train.squeeze(), s=np.ones(y_train.size), c=y_train.squeeze(), cmap='coolwarm') \n","ax.plot_surface(x_mesh, y_mesh, z_mesh, cmap='cool', linewidth=0, antialiased=False, alpha=0.4)\n","\n","ax.set_xlabel(f'Age ({age_train.max()} yrs)')\n","ax.set_ylabel(f'Mileage ({mileage_train.max()} miles)')\n","ax.set_zlabel(f'Price (${price_train.max()})')\n","ax.zaxis.labelpad = -0.5 # display z label\n","\n","# ax.view_init(elev=30, azim=-45)  # set elevation and azimuth of viewing angle\n"]},{"cell_type":"markdown","metadata":{},"source":["### Assess Model on Test Data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig = plt.figure()\n","fig.set_figwidth(7)\n","fig.set_figheight(7)\n","ax = fig.add_subplot(111, projection='3d')\n","# Define the grid of points for the plane\n","z_mesh = w[0, 0] * x_mesh + w[0, 1] * y_mesh + b\n","# Plot the data\n","ax.scatter3D(X_test[:, 0], X_test[:, 1], y_test.squeeze(), s=np.ones(y_test.size), c=y_test.squeeze(), cmap='coolwarm') \n","ax.plot_surface(x_mesh, y_mesh, z_mesh, cmap='cool', linewidth=0, antialiased=False, alpha=0.4)\n","\n","ax.set_xlabel(f'Age ({age_test.max()} yrs)')\n","ax.set_ylabel(f'Mileage ({mileage_test.max()} miles)')\n","ax.set_zlabel(f'Price (${price_test.max()})')\n","ax.zaxis.labelpad = -0.5 # display z label\n","\n","# ax.view_init(elev=30, azim=-45)  # set elevation and azimuth of viewing angle"]},{"cell_type":"markdown","metadata":{},"source":["## Sigmoid Activation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define ReLU function\n","def sigmoid(x):\n","    \"\"\" Sigmoid function\n","    Args:\n","        x: independent variable, could be an arrary of any shape or a scalar.\n","    Returns:\n","        y: dependent variable, could be an arrary of any shape or a scalar.\n","    \"\"\"\n","    y = 1 / (1 + np.exp(-x))\n","    return y\n","\n","# Define derivatives of ReLU function\n","def d_sigmoid(x):\n","    \"\"\" Derivative of sigmoid function\n","    Args:\n","        x: independent variable, could be an arrary of any shape or a scalar.\n","    Returns:\n","        dydx: dependent variable, could be an arrary of any shape or a scalar.\n","    \"\"\"\n","    dydx = sigmoid(x) * (1 - sigmoid(x))\n","    return dydx\n","\n","# Redefine forward pass. Intermediate result, Z, needs to be tracked \n","def forward(input, weight, bias):\n","    \"\"\" Model function\n","    Args:\n","        input: feature matrix (independent variables), 2d-array with shape (# samples, # features)\n","        weight: row vector of weights, 2d-array with shape (1, # features)\n","        bias: scalar\n","    Returns:\n","        output: column vector of predictions (sigmoid activated outcomes), 2d-array with shape (# samples, 1)\n","        Z: column vector of intermediate outputs, 2d-array with shape (# samples, 1)\n","    \"\"\"\n","    Z = linear(input, weight, bias)\n","    output = sigmoid(Z)\n","    return output, Z\n","\n","# Redefine gradient function. An exatra step to calculate dL/dZ will be added. \n","def grad(input, prediction, target, Z):\n","    \"\"\" Gradient function with sigmoid activation\n","    Args:\n","        prediction: column vector of predictions, 2d-array with shape (# samples, 1)\n","        target: column vector of ground truths, 2d-array with shape (# samples, 1)\n","        Z: column vector of intermediate outputs, 2d-array with shape (# samples, 1)\n","        feature: feature matrix, 2d-array with shape (# samples, # features)\n","    Returns:\n","        dw: row vector of MSE loss partial derivatives w.r.t. weights, 2d-array with shape (1, # features)\n","        db: scalar of MSE loss partial derivatives w.r.t. bias\n","    \"\"\"\n","    dZ = (prediction - target) * d_sigmoid(Z)\n","    dw = 1 / target.shape[0] * np.dot(dZ.T, input)\n","    db = dZ.mean()\n","    \n","    return dw, db\n","\n","# Optimization with ReLU activation\n","w = np.random.normal(0, 1e-4, (1, 2)) \n","b = np.random.normal(0, 1e-4)\n","print(f\"initial parameters: w = {w}, b = {b}\")\n","num_iters = 2000\n","learning_rate = 0.03\n","losses = []\n","for i in range(num_iters):\n","    y_pred, Z = forward(X_train, w, b)\n","    dw, db = grad(X_train, y_pred, y_train, Z)\n","    loss = mse_loss(y_pred, y_train)\n","    w = w - learning_rate * dw\n","    b = b - learning_rate * db\n","    print(f\"loss @ {i+1} iteration: {loss}\")\n","    # print(f\"w = {w}, b = {b}\")\n","    losses.append(loss)\n","print(f\"final parameters: w = {w}, b = {b}\")\n","\n","# Observe loss values\n","plt.plot(losses)"]},{"cell_type":"markdown","metadata":{},"source":["## Test Sigmoid Activated Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig = plt.figure()\n","fig.set_figwidth(7)\n","fig.set_figheight(7)\n","ax = fig.add_subplot(111, projection='3d')\n","# Define the grid of points for the plane\n","z_mesh = sigmoid(w[0, 0] * x_mesh + w[0, 1] * y_mesh + b)\n","# Plot the data\n","ax.scatter3D(X_test[:, 0], X_test[:, 1], y_test.squeeze(), s=np.ones(y_test.size), c=y_test.squeeze(), cmap='coolwarm') \n","ax.plot_surface(x_mesh, y_mesh, z_mesh, cmap='cool', linewidth=0, antialiased=False, alpha=0.4)\n","\n","ax.set_xlabel(f'Age ({age_test.max()} yrs)')\n","ax.set_ylabel(f'Mileage ({mileage_test.max()} miles)')\n","ax.set_zlabel(f'Price (${price_test.max()})')\n","ax.zaxis.labelpad = -0.5 # display z label\n","\n","ax.view_init(elev=30, azim=-45)  # set elevation and azimuth of viewing angle"]},{"cell_type":"markdown","metadata":{},"source":["Featurewise assessing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Visualize model on training data\n","fig, axs = plt.subplots(2,1)  # Initialize figures in 2 rows, 1 column\n","fig.set_figwidth(8)  # set figure size\n","fig.set_figheight(10)\n","axs[0] = plt.subplot(2,1,1)  # plot in the first figure\n","axs[0].plot(X_train[:, 0], y_train, '.', markersize=1)  # draw blue dots\n","axs[0].plot(X_train[:, 0], y_pred, 'r+', markersize=2)  # draw red '+' markers\n","axs[0].set(xlabel=f'Age (Unit: {age_train.max()} years)', ylabel=f'Price (Unit: ${price_train.max()})')  # label axes\n","axs[0].grid()\n","axs[1] = plt.subplot(2,1,2)\n","axs[1].plot(X_train[:, 1], y_train, '.', markersize=1)\n","axs[1].plot(X_train[:, 1], y_pred, 'r+', markersize=2)\n","axs[1].set(xlabel=f'Mileage (Unit: {mileage_train.max()} miles)', ylabel=f'Price (Unit: ${price_train.max()})')\n","axs[1].grid()"]},{"cell_type":"markdown","metadata":{},"source":["## ReLU Activation\n","Negative car price does not make sense. The output needs to be regulated to only output non-negative value."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define ReLU function\n","def relu(x):\n","    \"\"\" ReLU function\n","    Args:\n","        x: independent variable, could be an arrary of any shape or a scalar.\n","    Returns:\n","        y: dependent variable, could be an arrary of any shape or a scalar.\n","    \"\"\"\n","    # y = x.copy()\n","    y = x\n","    y[x<=0] = 0\n","    return y\n","\n","# Define derivatives of ReLU function\n","def d_relu(x):\n","    \"\"\" Derivative of ReLU function\n","    Args:\n","        x: independent variable, could be an arrary of any shape or a scalar.\n","    Returns:\n","        dydx: dependent variable, could be an arrary of any shape or a scalar.\n","    \"\"\"\n","    dydx = np.zeros_like(x)\n","    dydx[x>0] = 1\n","    return dydx\n","\n","# Redefine forward pass. Intermediate result, Z, needs to be tracked \n","def forward(input, weight, bias):\n","    \"\"\" Model function\n","    Args:\n","        input: feature matrix (independent variables), 2d-array with shape (# samples, # features)\n","        weight: row vector of weights, 2d-array with shape (1, # features)\n","        bias: scalar\n","    Returns:\n","        output: column vector of predictions (sigmoid activated outcomes), 2d-array with shape (# samples, 1)\n","        Z: column vector of intermediate outputs, 2d-array with shape (# samples, 1)\n","    \"\"\"\n","    Z = linear(input, weight, bias)\n","    output = relu(Z)\n","    return output, Z\n","\n","# Redefine gradient function. An exatra step to calculate dL/dZ will be added. \n","def grad(input, prediction, target, Z):\n","    \"\"\" Gradient function with sigmoid activation\n","    Args:\n","        prediction: column vector of predictions, 2d-array with shape (# samples, 1)\n","        target: column vector of ground truths, 2d-array with shape (# samples, 1)\n","        Z: column vector of intermediate outputs, 2d-array with shape (# samples, 1)\n","        feature: feature matrix, 2d-array with shape (# samples, # features)\n","    Returns:\n","        dw: row vector of MSE loss partial derivatives w.r.t. weights, 2d-array with shape (1, # features)\n","        db: scalar of MSE loss partial derivatives w.r.t. bias\n","    \"\"\"\n","    dZ = (prediction - target) * d_relu(Z)\n","    dw = 1 / target.shape[0] * np.dot(dZ.T, input)\n","    db = dZ.mean()\n","    \n","    return dw, db\n","\n","# Optimization with ReLU activation\n","w = np.zeros((1, 2)) + np.random.normal(0, 1e-4, (1, 2)) \n","b = 0 + np.random.normal(0, 1e-4)\n","num_iters = 2000\n","learning_rate = 0.02\n","losses = []\n","for i in range(num_iters):\n","    y_pred, Z = forward(X_train, w, b)\n","    dw, db = grad(X_train, y_pred, y_train, Z)\n","    loss = mse_loss(y_pred, y_train)\n","    w = w - learning_rate * dw\n","    b = b - learning_rate * db\n","    print(f\"loss @ {i+1} iteration: {loss}\")\n","    # print(f\"w = {w}, b = {b}\")\n","    losses.append(loss)\n","print(f\"updated w={w}, b={b}\")\n","print(f\"Model's mse on test data: {mse_loss(forward(X_test, w, b), y_test)}\")\n","\n","# Observe loss values\n","plt.plot(losses)"]},{"cell_type":"markdown","metadata":{},"source":["## Visualize ReLU Activated Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_test_pred, _ = forward(X_test, w, b)\n","print(f\"Model's mse on test data: {mse_loss(y_test_pred, y_test)}\")\n","\n","# Visualize model on two dimensions\n","y_test_pred, _ = forward(X_test, w, b)\n","fig, axs = plt.subplots(2,1)\n","fig.set_figwidth(8)\n","fig.set_figheight(10)\n","axs[0] = plt.subplot(2,1,1)\n","axs[0].plot(X_test[:, 0], y_test, '.', markersize=1)\n","axs[0].plot(X_test[:, 0], y_test_pred, 'r+', markersize=1)\n","axs[0].set(xlabel=f'Age (Unit: {age_train.max()} years)', ylabel=f'Price (Unit: ${price_train.max()})')\n","axs[1] = plt.subplot(2,1,2)\n","axs[1].plot(X_test[:, 1], y_test, '.', markersize=1)\n","axs[1].plot(X_test[:, 1], y_test_pred, 'r+', markersize=1)\n","axs[1].set(xlabel=f'Mileage (Unit: {mileage_train.max()} miles)', ylabel=f'Price (Unit: ${price_train.max()})')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig = plt.figure()\n","fig.set_figwidth(7)\n","fig.set_figheight(7)\n","ax = fig.add_subplot(111, projection='3d')\n","# Define the grid of points for the plane\n","z_mesh = relu(w[0, 0] * x_mesh + w[0, 1] * y_mesh + b)\n","# Plot the data\n","ax.scatter3D(X_test[:, 0], X_test[:, 1], y_test.squeeze(), s=np.ones(y_test.size), c=y_test.squeeze(), cmap='coolwarm') \n","ax.plot_surface(x_mesh, y_mesh, z_mesh, cmap='cool', linewidth=0, antialiased=False, alpha=0.4)\n","\n","ax.set_xlabel(f'Age ({age_test.max()} yrs)')\n","ax.set_ylabel(f'Mileage ({mileage_test.max()} miles)')\n","ax.set_zlabel(f'Price (${price_test.max()})')\n","ax.zaxis.labelpad = -0.5 # display z label\n","\n","ax.view_init(elev=30, azim=-45)  # set elevation and azimuth of viewing angle"]},{"cell_type":"markdown","metadata":{},"source":["## "]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"dl","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
